# 영역분할
1. 객체의 바운딩 박스뿐만 아니라 픽셀 단위 클래스 분류까지 -> 객체의 윤곽 구분
2. Segmantic segmentation : 객체단위가 아닌 하나의 클래스는 모두 같은 레이블
3. Instance segmentation : 객체 단위 다른 레이블

* Segmentation은 각각의 객체에 바운딩 박스만 찾는게 아니라 객체의 외곽선을 어느정도 정확히 윤곽을 따내는 결과가 나오도록 합니다. 

# Mask RCNN
1. Faster R-CNN을 이용해서 객체를 검출한다.(Object detection) (Resion proposal CNN)
2. FCN(Fooly convolutional Network) 

따라서 네트워크의 출력은 두개를 갖는다.
1. 객체의 바운딩박스 정보.
2. 각각의 바운딩 박스에 대해서 객체의 마스크맵을 출력


한 행렬에는
![image](https://user-images.githubusercontent.com/76835313/127810710-dfd5d413-b503-4eee-a9bb-1ed2f87c7da2.png)  

첫번째는 0이고, 클래스 ID, confidence값, 좌표

* maskThreshold : 0.3보다 크면 객체인부분 아니면 객체가 아닌부분이라고 판단한다.

# *** 선생
"마스크 RCNN 구조를 이해, 실습을 통해 이미지나 영상데이터에서 객체인식을해서 바운딩 박스까지한다." "데이터는 키티 데이터를 한다."
![image](https://user-images.githubusercontent.com/76835313/127819202-13dd2ba4-2f16-4447-819e-16ee7e4f6081.png)

"Mask RCNN을 하기위해 여러 패키지와 버전을 맞추어주어야 한다."

"COCO Weight는 COCO데이터의 약 80개정도 클래스를 가지고 있는 데이터셋에 대해서 학습한 weight이다. coco weight를 통해서 예측을 진행하면 학습한 모든클래스들을 예측을 인식할 수 있다."

![image](https://user-images.githubusercontent.com/76835313/127821667-d98247a9-b15d-4926-98d7-3e3e35e5619c.png)  
여기서 눈여겨 보실게 Detection_Min_Confidence와 Detection_NMS_Threshold정도가 되겠습니다. 
Detection_Min_Confidence에서 0.7은 최소 Confidence값 즉 이게 클래스 객체일 확률이 0.7 이상일 경우에만 객체라고 알려주는 것이구요.
Detection_NMS_Threshold의 경우 바운딩 박스가 30%이상 겹치게 되면 그 중에서 가장  Confidence값이 높은 바운딩박스만 남겨놓고 나머지는 무시하게됩니다. 
