### 가볍게 리뷰내용입니다. 내용이 엉성할 수 있습니다.

* 인공지능 : 기계 지능
1. 생명체 또는 인간이 갖고 있는 지능을 기계로 실현한 것
* 인공지능이 마음도 소유?
-> 앞으로의 연구

* AI의 발전

1. 앨런튜닝이 컴퓨터를 창시 : 1950
2. 1956 : 인공지능의 시작 
3. 1980 : AI의 암흑기
4. 1980s : 전문가 시스템(특정영역 : 법률과 의학분야)
5. 1990s : 암흑기
6. 2000 : 계속 AI에 관련된 연구 수행
7. 2006 : 딥러닝방식으로 해결가능해짐
8. 2010~ : 딥러닝

* AI의 기능 : 학습, 추론, 인지
1. 인공지능
2. 기계학습
3. 강화학습
4. 비지도학습
5. 지도학습
6. 딥러닝

* Neural Network 구조
1. 수사돌기 : 인접한 뉴런으로부터 신호가 세포체로 전달되는 통로
2. 세포체 : 신경세포의 중앙에위치 / 정보의 수용 연산 출력
3. 축색융기부 : 수상돌기를 통해 입력된 자극이 임계치를 넘으면 신경흥분을 전달, 낮으면 전달 X
4. 축색돌기 : 가늘고 긴 신경섬유로 인접한 뉴런으로 세포에 흥분을 전달
5. 시냅스 : 축색의 끝부분은 가느다란 가지로 나누어져 있고, 다른 뉴런의 수상돌기와 시냅스를 통해 연결
- 뉴런에서 뉴런으로 전달하는 부분
6. 뉴런의 정보교환 : 시냅스를 통해 수행

- 전기 신호에 의해 자극된 시냅스는 화학물질,신호를 방출한다.
- 흥분성 시냅스 : 시냅스 전 뉴런의 전기신호로 시냅스 후 전기신호의 전위를 올리는 경우
- 억제성 시냅스 : 시냅스 전 뉴런의 전기신호로 시냅스 후 전기신호의 전위를 내리는 경우

* 퍼셉트론 : 1943, 뇌의 뉴런 모델
- 다수의 인풋이 존재한다
- 가중치가 전달된다 : 시냅스와 관련된다.
- Suming junction : 수학적으로 표현가능하며 bias로 된다. 
- Activation function : 최종값을 결정하기 위함

* Summing junction에서 activationfunction이 적용되어 Output이 나오게된다. 

* XOR 또한 구현할 수 없는 모델이었다. 
-입력 두개와 weight, suming junction이 주어지고 값이 0.5보다 작으면 0 크면 1이라고 가정한다.
W0와 W1은 0.5보다 작아야하는데 W1과 W0자체는 0.5보다 커야한다. 따라서 간단한 XOR문제도 해결하지 못하는 문제가 있다. 그래서 이러한 문제를 해결하기 위해 2개 또는 3개의 Layer를 사용한다.
- 다층 퍼셉트론 : 3층 퍼셉트론으로 어떤 문제도 해결가능해진다

* Multi Later Perceptron
* MLP
- 입력층과 출력층 사이에 하나 이상의 은닉층을 가지는 전방향 신경회로망


# Artificial Inteligence 개요
1. Input layer 
2. Hidden Layer
3. Output Layer
입력에서 출력으로 향하는 방향 : Forward propagation

* sigmoid function
![image](https://user-images.githubusercontent.com/76835313/135761504-9456da77-4a21-42a9-a5c5-8e160579b769.png)

* z가 0이면 0.5가 되고 z가 커지면 1에수렴하고 음수가되면 무한대로 커져 0이된다.

* 학습 : Layer와 Layer를 연결하는 weight값을 우리가 원하는 output 값으로 만들어내나가는 과정

* Backpropagation 


* MSE(Mean Square Error)
- 양에러와 음에러
- 에러를 제곱을 취함으로써 모두 양의 값으로 바뀌어 소멸되는 오류를 방지할 수 있다. 
- 학습데이터를 이용하여 가중치 w와 바이어스 b를 변화시키는 과정을 반복적으로 수행하여 **cost function이 최소가 되도록 하는 것이 신경망 학습의 최종 목표**
- 뉴런과 입력의 개수가 많을 수록 복잡한 문제가 생긴다.
-> [BackPropagation](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)
-> [BackPropagation](http://galaxy.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html)  

* 경사하강법 : Gradient Descent Algorithm
![image](https://user-images.githubusercontent.com/76835313/135817714-75eb4be6-304b-4364-bfb8-0a2bbc8b9ef0.png)
- step을 통해서 Learning weight 값을 결정한다. 

* local 최저점에 빠지는 경우의 대책방안
- 이때는 스텝을 크게 가져가야한다.

* 인공지능 3대 요소기술
1. Learning 학습 : 사실과 규칙을 습득하는 일련의 과정
2. Inference 추론 : 주어진 사실이나 규칙으로부터 결론을 얻는 과정
3. Recognition 인식 : 분별하고 판단하는 과정

## 머신러닝
* 미셸 : 어떤 작업을 수행하는 머신의 성능을 P라고 했을 때, 경험 E를 통해 성능 P를 개선할 수 있다면 그 기계는 학습한다고 할 수 있다"라고 정의한다.

* 기계학습 시스템 : "주변환경 E에서 획득한 경험적 데이터 D를 기반으로 문제를 해결하는 모델 M을 자동으로 구성하고 또 스스로 성능 P를 향상하는 시스템"

* single Neuron
- 입력과 뉴런과의 연결

* DNN (Deep Neural Networks)

* RNN 순환신경망 (Recureent Neural Network)
* Softmax : 모든 출력의 합을 1로만들며 출력값을 0~1로 표현한다.

* 머신러닝 연구동향
1. 2005 : 방위고등연구계획국에서 Thrun에서 연설하며 자율주행 자동차를 연설
2. Deep Neural Networks 논문 발표. 힌튼은 암흑기에도 지속해서 연구
3. 2010 튜닝어워스를 학습분야에서 받는다.
4. 2009년 AI Lab의 기본은 머신러닝
5. 2013 페이스북 역시 AI Lab을 상업적으로 운영

* 머신러닝 분류
1. 지도 학습Supervised Learning
2. 비지도 학습
3. 강화 학습 : 자신과 환경과의 상호작용에 따라 행동을 개선해 나가는 학습 방법

머신러닝은 지도학습과 비지도로 분류되며

* 지도학습
1. 분류
2. 회귀
- 독립변수와 종속변수 간의 관계를 일반화하는 방법을 의미한다
- 일반회귀분석 : 등간, 비율척도
- 더미변수를 이용한 회뷔분석 : 명목, 서열척도 (성별이 임금수준에 영향을 미치는지에 대한 회귀분석)
- 독립변수와 종속변수의 관계에서 선형회귀에 집중한다.
* 비지도학습
- 데이터로부터 숨겨진 패턴 또는 규칙을 탐색하여 분류하는 학습방법
1. 군집

* workflow
1. 비지도학습과 지도학습으로 나뉜다.
2. 입력데이터 입력시 특징 추출
3. 알고리즘이 특정 객체로 그루핑

* 지도학습
- 입력데이터에 레이블 주고 트레이닝시킨다.
* 비지도 학습
- 입력데이터에 레이블이 없어서 같은 특징을 갖는것으로 분류해준다. 

* 비지도학습 클러스터링
1. 데이터 셋
2. 클러스터 개수 지정
3. 데이터를 클러스터 중심에 연결
4. 클러스터 중심을 할당된 데이터들의 중심으로 이동
5. 데이터를 클러스터 중심에 재할당
- 4,5번을 계속해서 반복한다. (클러스터 중심을 할당된 데이터들의 중심으로 이동, 데이터를 클러스터 중심에 재할당(Nearest))
* 강화학습
1. 알파고는 항상  관찰을 하며 평가한다.
2. 평가결과가 좋으면 1점을주고 나쁘면 -1, 평가가 불가능하면 0을 준다.
3. 1,2를 통해 다음단계에 반영한다.

1. 머신러닝으로 킬로미터를 마일로 바꾸어본다.
2. 100km를 0.5주면 50mile이다. 오차값은 12.137이다.
3. 오차를 보정하기위해 비례상수를 0.5에서 0.6을 준다.
4. 0.7을 비례상수로 준다. 오차가 -7.863이다.
5. 비례상수를 0.61로 준다. 오차가 1.137로 가능한범위안에 들어왔다. 경기도 용인시 기흥구 상하동

* Regression 용어
-> Regress 회귀의 원래 의미는 옛날 상태로 돌아가는 것이다.
- 따라서 부모와 자녀의 키 사이에는 선형적인 관계가 있고 키가 커지거나 작아지는 것보다는 전체 키 평균으로 돌아가려는 경향이 있다는 가설이다. -> 이건 올바른 가설은 아님
- 선형 회귀분석 : 독립변수와 종속변수 관계를 모델링하는 것이다.
- 1개의 독립변수에 기반한 경우에는 단순 선형회귀 분석
- 2개 이상의 돌립변수에 기반한 경우에는 다중 선형회귀 분석

* 예측값에서 실제값을 뺀것을 제곱한것을 다 더한후에 평균을 낸다.
* 예측값 H(x)=Wx+b
* 경사하강법으로 cost function을 최소화한다.

* Logistic Regression
- 스팸인지아닌지
- 페이스북을 보여줄지 숨길지
- 카드가 불법인지 아닌지
- 이것외에도 0~9까지 분류할때도 logistic regression을 사용가능하다.
- 기존시간 이상 공부하면 pass 아니면 fail

* Linear Regression은 y=x같은 직선으로는 불가능하다. 기울기 값을 변화시켜도 불가능하다. 
- 그래서 이때는 logistic regression을 사용해야 한다. 

-> Linear regression에서는 예측값이지만 Logistic Regression에서는 classification인 0 or 1이 출력된다. 

* sigmoid function으로 0~1로 modification 해준다.

* Multinomial classification
* ![image](https://user-images.githubusercontent.com/76835313/135875243-eed54615-8eb2-4bfc-ac52-e37542bb6b89.png)
하나의 직선으로는 분류할 수 없다. 하나의 직선으로 세개의 카테고리가 불가능하므로 먼저 A인지 아닌지를 구분, B인지 아닌지를 구분하는 직선, C인지 아닌지 구분하는 직선이 필요하다. 이러한 방식을 multinomial classification이라고 한다. 

# 딥러닝
* 머신러닝의 일종이다
* input layer와 output layer 사이에 존재하는 hidden layer의 수가 다수인 뉴럴네트워크이다.
* 레이어가 다수인 어마어마한 구조의 뉴럴네트워크에 엄청난 데이터를 마구 때려 넣는 방식으로 문제를 해결한다. 그래서 몇날 몇일을 학습하면 짜잔하고 최고의 결과를 내놓는다는 것이 곧 딥러닝이다.

* 딥러닝의 성공요인 4가지
1. 비지도 학습방법을 이용한 특징 추출
2. 컨볼루셔널 뉴럴 네트워크 CNN의 탄생
3. RNN(Recurrent Neural Network)의 발전
4. GPU 병렬 컴퓨팅의 등장 / 빠른 학습

* 딥러닝 역사
1. 1950년대까지는 인간의 뇌를 electronic brain으로 실제 구현할 수 있을까 하는 연구가 진행
2. 50년대 인공지능용어가 등장하며 57년 퍼셉트론 탄생(인류최초 뉴럴네트워크)
3. 60년대 adaline 탄생 (뉴럴네트워크가 하드웨어로 구현)
4. 1960~1970 황금이였으나 XOR을 해결할수없는 문제가 생김으로써 암픅기
5. 1986년 신경망(역전파)탄생
6. SVM탄생
7. 심층신경망인 딥러닝의 탄생 2006년

* 인풋과 아웃풋 사이에 다수의 레이어가 있다.

* 히든 레이어의 역할
1. 입력과 가까운 히든레이어
- 사람과 거리가 먼 기초적인 특징들 (에지)
2. 중간 히든레이어
- 중간레벨 특징들(눈, 코, 입)
3. 출력과 가까운 히든레이어
- 상위레벨 특징들 (얼굴)

* 딥러닝을 사용하지 않을때
- 입력 -> 수작업을 통한 특징 추출 -> 연산자(Classifier) -> 출력

* 딥러닝을 사용할 때
- 입력 -> 심층 아키텍처를 통한 특징 추출 -> 연산자 -> 출력
- 이미지 : 화소-> 모서리-> 물체의 일부분-> 물체
- 문자 인식 -> 글자 -> 단어 -> 구절 -> 문장
- 음성 인식 : 스펙트럼 대역 -> 단음 -> 음소 -> 단어

* CNN 
- 200 by 200 픽셀일때 구성단위는 40,000이다. 이때 매개변수는 20억개가 될 수 있다. 
- 이럴 경우, 공간 상관 관계, 자원의 낭비 + 충분히 훈련이 되지 못한다.
- 특정공간과 공간의 상관관계가 없어질 수 있다. 
- 사람은 일부분씩 훑어보여 영역의 특징을 모아 전체의 특징을 분석한다. 

* CNN의 필요성
- 구성단위가 40,000이어도 필터사이즈를 10 by 10으로 하면 매개변수를 20억에서 4,000,000으로 줄일 수 있다.

* One-Hot Encoding

![image](https://user-images.githubusercontent.com/76835313/135884020-6abe27f9-827a-4be1-ae72-3882699892e8.png)

* Gradient Descent
1. cost는 loss를 의미한다. loss를 최소화해야한다.
2. 최솟값은 접선의 기울기가 0이되는 지점인데 이곳이 cost가 0이다.
3. 미분을 하면서 주어진 weight 값을 계속해서 보정해 나아간다.
4. 그 값이 0이되면 학습이 끝난다.
5. 알파는 학습률이다.
![image](https://user-images.githubusercontent.com/76835313/135884184-a1080bf5-7fab-4028-94ec-ce6aeb93a9c4.png)

* Learning rate : 알파?
1. 작게 설정하면 학습시간이 오래걸린다.
2. 크게하면 계속해서 반복하기 또 오래걸린다.(자꾸 최저점을 지나가므로)
- 따라서 지속적인 체크와 지속적인 관찰이 필요하다.

* Overfitting
- +기호와 -기호를 정확하게 분류할때, 직선으로 구분하면  한쪽은 정답을 맞출수있지만 한쪽은 에러가 있을 수도 있다.
- 그래서 학습모델은 곡선으로 피팅할 수 있다. 특정데이터에 부합한 곡선을 만드는 것이다. 

* 솔루션
- 더 많은 데이터로 학습시킨다. 
- feature(독립변수)의 개수를 줄인다.(키,신장,발사이즈가 수명에 영향을 끼친다할때 발사이즈까지 적으면 특정 특징에 편향되어 overfitting이 일어날 수 있다. 그때 발사이즈를 제거한다.)

![image](https://user-images.githubusercontent.com/76835313/135887487-83b964b1-62c3-4984-8535-a981f1337e5e.png)

- Regularization
1. 일반화 시킨다. cost function의 값이 최소화되어야한다.
2. Wx+b 예측값과 실체값의 차이이며 Regularizaiton은 마지막항이다. 오버피팅이 일어나는것을 방지하기 위해 Weight을 줄이도록 학습한다.  람다는 Regularization 강도를 결정한다. 1일경우 강하다. 0이면 안한다.

* MNIST Dataset
1. 트레이닝 데이터 셋
2. 트레이닝 레이블(정답) 저장된 파일
3. 테스트 데이터 셋
4. 테스트 데이터 레이블 저장된 파일 -> 평가한다.

* 데이터는 ratation, shearing, translation, scaling을 한다. 

* Activation Function
1. Sigmoid function
- 비선형함수이므로 아무런 의미가 없다라며 지적
- 일정 학습횟수가 지나가더라도 sigmoid function이 cost function을 줄이는 효과가 없다.
2. Relu Function
- 비선형을 선형으로 바꾸자 : 뉴런에 입력되는 데이터가 음수면 0이고 양수면 그대로 출력한다. 
- ReLU function을 사용하면 학습 초기에 급격하게 cost function이 줄어든다.
- 에러가 급격히 줄어든다. 
3. tanh
4. Maxout
5. ELU

* weight의 값을 어떻게 설정할 것인가?

* Vanishing gradient
- 인풋과 아웃풋 사이 히든레이어가 많다
- 최종오차는 출력단에서 알 수 있으므로 웨이트값을 트레이닝시킨다.
- 웨이트의 변화율은 계층마다 미분하는데 어느단계에서 0에가까워진다.
- 그렇기 때문에 NN은 제 2의 암흑기로 갔다. 1986~2006(힐튼 교수의 논문발표)

* weight의 초기값 구하기

* Dropout : NN에서 오버피팅을 방지하기 위한 방법
- 뉴런의 연결은 전체적으로 연결된다. 그러나 모든 뉴런을 고려할 필요가없다.
- 실질적 역할을 하지않으면 끊어낸다. 남는 나머지 뉴런만 연결한다. 

* 하이퍼 파라미터 : 학습을 통해서 최적화하는 변수가 아니라 실험적 즉 경험적 지식(priori)으로 설정해야 하는 변수
1. Learning rate : 학습률
2. Regularization Parameter : Overfitting 문제의 극복
3. Hidden Layer의 개수
- Hidden layer의 개수가 많아질수록 특정 트레이닝 데이터에 최적화
- 모든 Hidden layer에 있는 뉴런의 개수가 Input layer에 있는 뉴런의 개수보다 많은 것이 효과적
4. 가중치 초기화
- 바이어스 : 0으로 초기화
- 가중치의 초기화 : 다양한 경험적 알고리즘이 존재

# CNN  : Convolutional Neural Network
* 기존의 영상처리 방법
- 입력영상이 들어오면 오브젝트의 특징을 추출한다. 추출된 특징에 따라서 object들을 분류합니다.
- 단 세개의 레이어만으로도 영문자 대문자 A를 인식하는데 바이어스와 가중치 총계는 28,326개이다. 

1. 전처리 입력영상으로 특징추출
2. shift와 distortion invariance 처리를한다. 
3. classification으로 분류하면 
4. 최종 아웃풋이 된다. 

1, 입력영상이 주어지면 특징을 추출한다
2. featuremap을 생성한다. 4개
3. 다시 크기를 축소하는 subsampling을 수행한다.
4. 다시 convolution으로 특징을 추출한다.
5. 그리고 다시 크기를 축소하는 subsampling을 수행한다.
6. 다시 convolution처리해서 1차원 데이터로 바꾼다.

* Mask Patter대신에 딥러닝에서는 필터, 커널이라고 표현한다.
* 중심점설정이 용이한 이유로 3 by 3 등 홀수가 일반적이다. 

* 마스크 패턴대신에 필터라는 용어를 사용한다.
- Filter Sliding 
![image](https://user-images.githubusercontent.com/76835313/135899316-3676164e-1d54-4fe5-9a01-f2509f33e2b9.png)


* CNN의 기본구조
1. CONV : 특징추출
2. RELU : 
3. CONV
4. RELU
5. POOL : 영상의 크기를 축소시킴 (차원을 축소)
6. CONV
7. RELU
8. CONV
9. RELU
10. POOL
11. CONV
12. RELU
13. CONV
14. RELU
15. POOL
16. Fully connected Layer

![image](https://user-images.githubusercontent.com/76835313/135901061-b862f70d-cd36-462f-bf24-8431969cfdb0.png)
1. MAX pooling
2. Average Pooling
3. Min Pooling 

딥러닝에서는 max pooling으로 한다. 풀링을 수행함으로써 4 by 4가 2by2로 디맨젼 축소가 된다.

* AlexNet
* AlphaGo

* CNN Hyper parameter
1. Filter의 개수
2. layer의 depth가 커질수록 작아진다.
3. 일반적으로 영상의 크기가 큰 입력단 근처에 있는 layer는 filter의 개수가 적고, 입력단에서 멀어질수록 filter의 개수는 증가하는 경향이있다.
4. 각 단에서의 연산 시간/량을 비교적 일정하게 유지하여 시스템의 균형을 맞춘다.
5. 이를 위해 일반적으로는 각 layer에서 feature map의 개수와 pixel 수의 곱을 대략적으로 일정하게 유지한다.

* Filter의 형태
1. 일반적으로 크기가 작으면 5x5 필터를 주로 사용한다. 
2. 여러개의 작은 크기의 필터를 중첩해서 사용하는 것이 좋다.

* Stride 값 : Stride는 convolution을 수행할 때, 건너 뛸 픽셀의 개수를 결정한다. 
- Stride는 입력 영상의 크기가 큰 경우, 연산량을 줄이기 위한 목적으로 입력단과 가까운 쪽에만 적용
- stride를 1로 하고, pooling을 통해 적절한 sub-sampling 과정이다. 

* Zero-padding 지원 여부
- 32x32 입력 영상에 대해 커널의 크기가 5x5인 convolution을 적용하면 feature map의 크기가 28x28로 줄어 들었고, 14x14 영상에 대해 다시 5x5 convolution을 수행하면 결과는 10x10으로 줄어드는 것을 볼 수가 있다.
- 경계면의 정보까지 살릴 수가 있어 zero-padding을 지원하지 않는 경우에 비해 zero-padding을 지원하는 것이 좀 더 결과가 좋다.

* Sequence data : 동영상 or 음성데이터

* RNN : 데이터의 반복적인 패턴을 탐색
![image](https://user-images.githubusercontent.com/76835313/135906838-77162330-fc16-42a5-96cb-c34d128600e2.png)
x0가 먼저 발생하며 히든 레이어 A에 들어가면 output h0가 발생한다. 그리고 h1은 x1에 의해서만 결정되는게 아니라 과거의 출력도 영향을 받는다.
- RNN에서는 ReLU보다는 tanh를 더 많이 사용한다. 

* Vanilla RNN : 히든레이어가 한개이다.


![image](https://user-images.githubusercontent.com/76835313/135908644-779467f3-eac4-4899-b5d3-d5d104b0292b.png)
I는 그냥 대명사로 나올수있지만 work의 경우 이전의 I에 영향을 받아 동사임을 알아낸다.

* RNN 응용
1. Language Modeling : 문장 구조 분석
2. Speech Recognition : 대화 내용 인식
3. Machine Translation : 문장 번역
4. Conversation Modeling/Question Answering : 대화 모델링, 질문 대답
5. Image/Video Captioning : 동영상 캡셔닝
6. Image/Music/Dance Generation : 이미지, 음악 생성 등


* Multi-Layer RNN
- 히든레이어는 하나일 필요없이 depth를 CNN처럼 깊게 설정할 수 있다. 

* 텐서플로
1. 구글에서 개발
2. 딥러닝 시스템 구현을 위한 open source library
3. 텐서플로 자체는 기본적으로 C++
4. 파이썬 라이브러리가 주로 활용

1. Tensorflow 커널은 파이썬을 이용해서 접근할 수 있다. 
2. mid level에서도 layers, datasets,metrics가 있다.
3. high level에는 Estimators영역으로 training, evaluation, prediction

* 노드는 곱하고, 나누는 등 텐서를 처리하는 연산.
* 엣지는 텐서를 의미하며 엣지의 방향은 텐서의 흐름이다.
* 텐서는 데이터의 다차원 배열이다.

* TF example
tf.placeholder는 메모리를 할당한다.

* Epoch : 모든 데이터 셋을 한 번 학습

* 단일 계측 AND Logic Simple Neural Network

* 우리의 목표는 costfunction과 bias를 최소화 하는 것.

* 다중 변수 : 입력변수가 여러개이다. 
* 입력변수가 여러개일 경우 행렬로 표현한다. 
* Gradient decent : 경사를 하강시켜나가면서 기울기가 0인 지점을 찾는다. 여기가 에러가 없다. 더이상 학습이 필요가 없다. 







